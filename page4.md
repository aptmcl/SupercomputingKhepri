@def title = "Optimization"

```julia:setup
#hideall
using DataFrames
using CSV
using Plots
using StatsPlots
using Statistics
using JSON

plotlyjs(size=(640,330))

bench_data(str) =
  DataFrame(CSV.File(IOBuffer(str), delim=" ", ignorerepeated=true))

saveplot(plt, name="", ext="svg") =
  fdplotly(json(Plots.plotlyjs_syncplot(plt))) # hide
  #savefig(joinpath(@OUTPUT, name * "." * ext))
```

# Optimization

The next set of experiments measured the potential gains that
parallelization could provide to optimization problems. To focus on
the optimization itself, we used an objective function that was not
parallelized. More specifically, the case study was the optimization
of the structural properties of the previous truss, measured by the
maximum displacement of all its nodes. The variable vector to optimize
is the location of the truss' center, i.e., the point at the top where
all truss legs join.

We started by considering only the X and Y coordinates of the truss'
center, fixing its height. This means we have two variables
to optimize. The objective function landscape is a very simple one,
as represented in the following plot where we show the maximum
displacement of the truss nodes for different locations $(X,Y)$ (at a
fixed height) of the truss' central node.

```julia:truss_center
#hideall
plot_2d(raw_data) =
  let data = raw_data
    plot(-6.0:0.5:6.0,
         -6.0:0.5:6.0,
         reshape(data[:,3], (25, 25)),
         st=:surface,
         #legend=:none,
         #markers=:auto,
         #ylimits=(0,180),
         xlabel="X",
         ylabel="Y",
         zlabel="Max Displacement",
         #color=:green,
         #xscale=:log10,
         )
  end

plt = plot_2d(bench_data("""
X Y MaxDisplacement
-6.0 -6.0 0.17019783521210327
-6.0 -5.5 0.1575668173538984
-6.0 -5.0 0.14574156707203664
-6.0 -4.5 0.13480812059062885
-6.0 -4.0 0.12474320429632176
-6.0 -3.5 0.11552573430065137
-6.0 -3.0 0.1095088058068711
-6.0 -2.5 0.10563325707954485
-6.0 -2.0 0.1026045115073573
-6.0 -1.5 0.10039943784349667
-6.0 -1.0 0.09897436454036211
-6.0 -0.5 0.0982814815426216
-6.0 0.0 0.09827775058033124
-6.0 0.5 0.09892536776306275
-6.0 1.0 0.10018821658287994
-6.0 1.5 0.10202912063800543
-6.0 2.0 0.10441033077261186
-6.0 2.5 0.10729788725487692
-6.0 3.0 0.11067150027673552
-6.0 3.5 0.11454580232743694
-6.0 4.0 0.11901390037590893
-6.0 4.5 0.12439409457484084
-6.0 5.0 0.13327089723036029
-6.0 5.5 0.14393466659539453
-6.0 6.0 0.15612288688561826
-5.5 -6.0 0.15821646956402813
-5.5 -5.5 0.1464248368354598
-5.5 -5.0 0.1352039035077912
-5.5 -4.5 0.12468591345928191
-5.5 -4.0 0.114963036711939
-5.5 -3.5 0.10608820550935
-5.5 -3.0 0.0983697322791679
-5.5 -2.5 0.09459614895205523
-5.5 -2.0 0.0916050084129462
-5.5 -1.5 0.08938881837012068
-5.5 -1.0 0.08792253414122901
-5.5 -0.5 0.08717205025866469
-5.5 0.0 0.08710073235948983
-5.5 0.5 0.0876723623355891
-5.5 1.0 0.08885189297685962
-5.5 1.5 0.09060647301770244
-5.5 2.0 0.0929087422962224
-5.5 2.5 0.09574379744269902
-5.5 3.0 0.09912141397963785
-5.5 3.5 0.1030954688500291
-5.5 4.0 0.10778972448145083
-5.5 4.5 0.11462354609699721
-5.5 5.0 0.12356684426980219
-5.5 5.5 0.1339136615767626
-5.5 6.0 0.1453980672885024
-5.0 -6.0 0.147994153174528
-5.0 -5.5 0.1365128369730352
-5.0 -5.0 0.12565956312880908
-5.0 -4.5 0.11549134527259564
-5.0 -4.0 0.10604087185658491
-5.0 -3.5 0.09737860158585551
-5.0 -3.0 0.0895693074544651
-5.0 -2.5 0.08427090386398013
-5.0 -2.0 0.08130545481043368
-5.0 -1.5 0.07907372817910494
-5.0 -1.0 0.07756500517013097
-5.0 -0.5 0.07675793205485065
-5.0 0.0 0.07662486455161217
-5.0 0.5 0.07713538196550514
-5.0 1.0 0.07825925076155127
-5.0 1.5 0.07996992627015308
-5.0 2.0 0.08224972276469796
-5.0 2.5 0.08509744387210633
-5.0 3.0 0.08853872220160097
-5.0 3.5 0.09263790006178933
-5.0 4.0 0.09781674660617164
-5.0 4.5 0.10551448187878702
-5.0 5.0 0.11433512221929655
-5.0 5.5 0.12434264774220076
-5.0 6.0 0.13533179281369154
-4.5 -6.0 0.13965953077476367
-4.5 -5.5 0.12805908940892607
-4.5 -5.0 0.11729288605633417
-4.5 -4.5 0.10729104569690083
-4.5 -4.0 0.09802893915529158
-4.5 -3.5 0.08950419381654011
-4.5 -3.0 0.08177500884984966
-4.5 -2.5 0.07490381359077981
-4.5 -2.0 0.07169193422099356
-4.5 -1.5 0.06942577236048632
-4.5 -1.0 0.06786470009526971
-4.5 -0.5 0.06699935679598634
-4.5 0.0 0.06681203275903132
-4.5 0.5 0.06727971896640324
-4.5 1.0 0.06837788685413312
-4.5 1.5 0.07008523852232737
-4.5 2.0 0.07238962723099912
-4.5 2.5 0.07529500320967028
-4.5 3.0 0.07882853811664114
-4.5 3.5 0.08304572044020725
-4.5 4.0 0.0893791674107572
-4.5 4.5 0.09701040107605656
-4.5 5.0 0.1056467214197882
-4.5 5.5 0.11530855077498124
-4.5 6.0 0.12587742323218035
-4.0 -6.0 0.13274880711634998
-4.0 -5.5 0.12092034796939763
-4.0 -5.0 0.11008047467598864
-4.0 -4.5 0.1000979042755253
-4.0 -4.0 0.09090072803282381
-4.0 -3.5 0.08245469780885431
-4.0 -3.0 0.07475051465126409
-4.0 -2.5 0.06784667263806873
-4.0 -2.0 0.06275668939113928
-4.0 -1.5 0.06042306400577937
-4.0 -1.0 0.05878885914054229
-4.0 -0.5 0.05785679988667314
-4.0 0.0 0.05761969919882199
-4.0 0.5 0.058062162305724356
-4.0 1.0 0.05916416867334297
-4.0 1.5 0.06090626411201784
-4.0 2.0 0.0632757205382708
-4.0 2.5 0.06627265535566831
-4.0 3.0 0.06991469756057134
-4.0 3.5 0.07491536789194332
-4.0 4.0 0.08159566749476418
-4.0 4.5 0.08912143190625961
-4.0 5.0 0.09754830054418889
-4.0 5.5 0.10686238694667549
-4.0 6.0 0.11707750054145451
-3.5 -6.0 0.12682579665419258
-3.5 -5.5 0.11484111644492402
-3.5 -5.0 0.10388955702336032
-3.5 -4.5 0.09384802178008067
-3.5 -4.0 0.08462866863174931
-3.5 -3.5 0.07617710325730927
-3.5 -3.0 0.06846639714763651
-3.5 -2.5 0.06149215799611488
-3.5 -2.0 0.055325878809792846
-3.5 -1.5 0.05204862825663532
-3.5 -1.0 0.0503077910172785
-3.5 -0.5 0.04929087744242297
-3.5 0.0 0.049007306587357934
-3.5 0.5 0.04943953695735311
-3.5 1.0 0.05058132892639331
-3.5 1.5 0.05240286157220822
-3.5 2.0 0.05488343566842728
-3.5 2.5 0.058011022776898284
-3.5 3.0 0.06193564266335145
-3.5 3.5 0.06786334682565535
-3.5 4.0 0.07452266655127604
-3.5 4.5 0.08193742887883029
-3.5 5.0 0.09011959099951161
-3.5 5.5 0.10014608879135209
-3.5 6.0 0.11127037675032801
-3.0 -6.0 0.12165618260334513
-3.0 -5.5 0.1096132909207199
-3.0 -5.0 0.09857304266263886
-3.0 -4.5 0.08844895640818418
-3.0 -4.0 0.07916036026506072
-3.0 -3.5 0.07064627291605734
-3.0 -3.0 0.06286874136117454
-3.0 -2.5 0.05581317221908446
-3.0 -2.0 0.0494890200005611
-3.0 -1.5 0.044313770244764246
-3.0 -1.0 0.04242274151989389
-3.0 -0.5 0.04129584953573479
-3.0 0.0 0.040954459146058234
-3.0 0.5 0.04139899109386248
-3.0 1.0 0.04260924317570849
-3.0 1.5 0.04455093866805207
-3.0 2.0 0.047185623419657444
-3.0 2.5 0.05047986905462374
-3.0 3.0 0.05550705466960598
-3.0 3.5 0.06148787827740019
-3.0 4.0 0.06813517592728342
-3.0 4.5 0.07594853075116477
-3.0 5.0 0.08535254368666577
-3.0 5.5 0.09550020569389714
-3.0 6.0 0.10633908414900844
-2.5 -6.0 0.11714777267800947
-2.5 -5.5 0.10510948226840543
-2.5 -5.0 0.09401569059468907
-2.5 -4.5 0.08381458140535238
-2.5 -4.0 0.07444040605040476
-2.5 -3.5 0.06583345862865907
-2.5 -3.0 0.057949799414076644
-2.5 -2.5 0.05076655032494465
-2.5 -2.0 0.0442868044619911
-2.5 -1.5 0.03856676139614342
-2.5 -1.0 0.035098210715134526
-2.5 -0.5 0.03380609799180369
-2.5 0.0 0.033386498523752715
-2.5 0.5 0.03385228678860737
-2.5 1.0 0.03517554735280884
-2.5 1.5 0.037297794721295206
-2.5 2.0 0.040148681080325974
-2.5 2.5 0.0443096802735
-2.5 3.0 0.049756418368542346
-2.5 3.5 0.05581471150355281
-2.5 4.0 0.06373522854051614
-2.5 4.5 0.0723857566837057
-2.5 5.0 0.08173465394715376
-2.5 5.5 0.09178620494163099
-2.5 6.0 0.10248759497463344
-2.0 -6.0 0.1132775375944251
-2.0 -5.5 0.10126214777437495
-2.0 -5.0 0.09014198183872237
-2.0 -4.5 0.07988049817298795
-2.0 -4.0 0.07042435440597433
-2.0 -3.5 0.06171670279181853
-2.0 -3.0 0.05370939669459762
-2.0 -2.5 0.04637125201412337
-2.0 -2.0 0.03969620754162407
-2.0 -1.5 0.033715193977161724
-2.0 -1.0 0.02858799143955769
-2.0 -0.5 0.026790056623899643
-2.0 0.0 0.026256408579795297
-2.0 0.5 0.026764064724955173
-2.0 1.0 0.02826667129959141
-2.0 1.5 0.030656036712218553
-2.0 2.0 0.034091546034044067
-2.0 2.5 0.039109764604222545
-2.0 3.0 0.04536247930021404
-2.0 3.5 0.0528254257656633
-2.0 4.0 0.060902934640743325
-2.0 4.5 0.06964109419613715
-2.0 5.0 0.0790297182165075
-2.0 5.5 0.08905482506128172
-2.0 6.0 0.09973574843558164
-1.5 -6.0 0.11048617993781978
-1.5 -5.5 0.09829030375707755
-1.5 -5.0 0.08696947871280088
-1.5 -4.5 0.07661579199149238
-1.5 -4.0 0.06708457727115333
-1.5 -3.5 0.05828684965226571
-1.5 -3.0 0.05016022199141015
-1.5 -2.5 0.04266361433080543
-1.5 -2.0 0.03577699601908835
-1.5 -1.5 0.02955794155529642
-1.5 -1.0 0.02403365846937911
-1.5 -0.5 0.020328717011146254
-1.5 0.0 0.019636430355783715
-1.5 0.5 0.020219692444574083
-1.5 1.0 0.02198975490652518
-1.5 1.5 0.024772220407754487
-1.5 2.0 0.02946087158662226
-1.5 2.5 0.03594530886225149
-1.5 3.0 0.04300690612070368
-1.5 3.5 0.05062960591039485
-1.5 4.0 0.05885735427298579
-1.5 4.5 0.06768544018108497
-1.5 5.0 0.07712263630569899
-1.5 5.5 0.08719921416967288
-1.5 6.0 0.0979557567434935
-1.0 -6.0 0.10872378152278311
-1.0 -5.5 0.09651493100411668
-1.0 -5.0 0.08514974448818985
-1.0 -4.5 0.07460506254898111
-1.0 -4.0 0.06483391102958495
-1.0 -3.5 0.055778765030445925
-1.0 -3.0 0.04738151896788884
-1.0 -2.5 0.039699358912238025
-1.0 -2.0 0.03264990215585223
-1.0 -1.5 0.02616350999173534
-1.0 -1.0 0.020289574828120632
-1.0 -0.5 0.015252514420841592
-1.0 0.0 0.013462920811919691
-1.0 0.5 0.01418794314712007
-1.0 1.0 0.016433948663187373
-1.0 1.5 0.021292958174214605
-1.0 2.0 0.027435283245282927
-1.0 2.5 0.034192740991204486
-1.0 3.0 0.04143991913801628
-1.0 3.5 0.0491938206300848
-1.0 4.0 0.057534541361502184
-1.0 4.5 0.06644613833098567
-1.0 5.0 0.07596536029092937
-1.0 5.5 0.08613429311785925
-1.0 6.0 0.09700408445986619
-0.5 -6.0 0.10758518486723827
-0.5 -5.5 0.09536200905182413
-0.5 -5.0 0.08398201057302118
-0.5 -4.5 0.07341267235114216
-0.5 -4.0 0.06360201093255315
-0.5 -3.5 0.05448847576179011
-0.5 -3.0 0.04600814041568462
-0.5 -2.5 0.03813673151991051
-0.5 -2.0 0.030788969483432335
-0.5 -1.5 0.02391387045131318
-0.5 -1.0 0.01764853110488434
-0.5 -0.5 0.012046021250470365
-0.5 0.0 0.008162959089628483
-0.5 0.5 0.009119180644038518
-0.5 1.0 0.01403589314824849
-0.5 1.5 0.019934833749837993
-0.5 2.0 0.026340557305669393
-0.5 2.5 0.033254998096114534
-0.5 3.0 0.04061852714828045
-0.5 3.5 0.048484890528232884
-0.5 4.0 0.05688516522892286
-0.5 4.5 0.06588148943276928
-0.5 5.0 0.07549131822402397
-0.5 5.5 0.08576058178678074
-0.5 6.0 0.09673804812149132
0.0 -6.0 0.10707072911947783
0.0 -5.5 0.09484103793276807
0.0 -5.0 0.08346671480161341
0.0 -4.5 0.07290424288139026
0.0 -4.0 0.06309653733370096
0.0 -3.5 0.05397984575538557
0.0 -3.0 0.04549107681736916
0.0 -2.5 0.03761084336371327
0.0 -2.0 0.030227399409589108
0.0 -1.5 0.023318450733320534
0.0 -1.0 0.01695202202108289
0.0 -0.5 0.011052227769446333
0.0 0.0 0.007271440482137469
0.0 0.5 0.008773348846545832
0.0 1.0 0.013869569780488533
0.0 1.5 0.019836537418009326
0.0 2.0 0.026212052742700557
0.0 2.5 0.033166944495657644
0.0 3.0 0.04059836069570546
0.0 3.5 0.048519523971453364
0.0 4.0 0.05697240411007191
0.0 4.5 0.06600046755265539
0.0 5.0 0.07568377428781183
0.0 5.5 0.0860535605274415
0.0 6.0 0.09712797928627531
0.5 -6.0 0.10720378324587279
0.5 -5.5 0.09500303342512119
0.5 -5.0 0.08367519615799643
0.5 -4.5 0.07316790957167084
0.5 -4.0 0.06342135958337652
0.5 -3.5 0.05437276947932982
0.5 -3.0 0.045960492797440605
0.5 -2.5 0.03812802047490103
0.5 -2.0 0.03085736678981002
0.5 -1.5 0.02411247341627147
0.5 -1.0 0.017974125708771715
0.5 -0.5 0.013661147162532439
0.5 0.0 0.011725356341413144
0.5 0.5 0.012105543758859642
0.5 1.0 0.01576511953919886
0.5 1.5 0.021365164790939417
0.5 2.0 0.02761000351854244
0.5 2.5 0.03446449011023478
0.5 3.0 0.04180917125117347
0.5 3.5 0.04966733949577693
0.5 4.0 0.05807385088564479
0.5 4.5 0.06706799207287445
0.5 5.0 0.076731896918008
0.5 5.5 0.08707225789292637
0.5 6.0 0.09809698449682275
1.0 -6.0 0.10809206780060748
1.0 -5.5 0.09591898937325483
1.0 -5.0 0.08463425185886093
1.0 -4.5 0.07418354896300697
1.0 -4.0 0.06450878598235009
1.0 -3.5 0.0555519007103308
1.0 -3.0 0.04725955306562868
1.0 -2.5 0.039588911977584816
1.0 -2.0 0.03251663316489984
1.0 -1.5 0.026175807904504043
1.0 -1.0 0.02204108944470367
1.0 -0.5 0.019206972412155552
1.0 0.0 0.017686846244888574
1.0 0.5 0.01773535875458149
1.0 1.0 0.02017916842325401
1.0 1.5 0.024506185406697144
1.0 2.0 0.029963915414785134
1.0 2.5 0.03661613908464238
1.0 3.0 0.04386482779702059
1.0 3.5 0.05168365696768594
1.0 4.0 0.06009330549961734
1.0 4.5 0.06912392408163998
1.0 5.0 0.07885716820863939
1.0 5.5 0.089277789418935
1.0 6.0 0.10038562256974029
1.5 -6.0 0.10969570146235957
1.5 -5.5 0.09755345382140833
1.5 -5.0 0.0863134167724146
1.5 -4.5 0.07592679028678595
1.5 -4.0 0.0663401957096629
1.5 -3.5 0.057501893632431654
1.5 -3.0 0.04936832418138284
1.5 -2.5 0.04191163805555201
1.5 -2.0 0.03588901402504139
1.5 -1.5 0.03135451075452821
1.5 -1.0 0.02790537411037277
1.5 -0.5 0.025417909107605708
1.5 0.0 0.024094503409369514
1.5 0.5 0.02402027642100193
1.5 1.0 0.025392511625557328
1.5 1.5 0.029338348375894416
1.5 2.0 0.034156673835203176
1.5 2.5 0.03967740498176871
1.5 3.0 0.04661543190790419
1.5 3.5 0.05435044871002407
1.5 4.0 0.06272586916200133
1.5 4.5 0.07176636858024663
1.5 5.0 0.0815427337087306
1.5 5.5 0.09202669272463108
1.5 6.0 0.1032144899916712
2.0 -6.0 0.11211677153456547
2.0 -5.5 0.0999747239110113
2.0 -5.0 0.08875932423879199
2.0 -4.5 0.0784283148550871
2.0 -4.0 0.06893138431992522
2.0 -3.5 0.060221472435737
2.0 -3.0 0.05297206789974298
2.0 -2.5 0.04652531213642657
2.0 -2.0 0.04156513392548718
2.0 -1.5 0.03764349872550263
2.0 -1.0 0.03451799462307812
2.0 -0.5 0.03228977973899729
2.0 0.0 0.031058198832362025
2.0 0.5 0.030886281052488872
2.0 1.0 0.031849190294880286
2.0 1.5 0.034852356567882534
2.0 2.0 0.039415688650527886
2.0 2.5 0.04471364090156447
2.0 3.0 0.050684207885912554
2.0 3.5 0.05766358015816188
2.0 4.0 0.06600402557815238
2.0 4.5 0.07504050964807539
2.0 5.0 0.08479497582052278
2.0 5.5 0.09532483171541185
2.0 6.0 0.10659349593838281
2.5 -6.0 0.11544894835908838
2.5 -5.5 0.10323721915464373
2.5 -5.0 0.09200707191751643
2.5 -4.5 0.08170968860106498
2.5 -4.0 0.07302077447017416
2.5 -3.5 0.06523227458753825
2.5 -3.0 0.058210036629209504
2.5 -2.5 0.05275569499360017
2.5 -2.0 0.04834671543578368
2.5 -1.5 0.04465377470368196
2.5 -1.0 0.04173749890560954
2.5 -0.5 0.039669843305728016
2.5 0.0 0.03849284382653768
2.5 0.5 0.03824049132138307
2.5 1.0 0.038914262793768514
2.5 1.5 0.04097985118024086
2.5 2.0 0.04532735985363559
2.5 2.5 0.05043698944729149
2.5 3.0 0.05626061989202589
2.5 3.5 0.06277084970311202
2.5 4.0 0.06995754944389775
2.5 4.5 0.07891404078971344
2.5 5.0 0.08868129120508479
2.5 5.5 0.09921458123998887
2.5 6.0 0.1105381559694318
3.0 -6.0 0.11971588966020465
3.0 -5.5 0.10735592345810148
3.0 -5.0 0.09692624232102312
3.0 -4.5 0.08748997620239433
3.0 -4.0 0.07892394773064822
3.0 -3.5 0.07116265765227879
3.0 -3.0 0.06514108909731955
3.0 -2.5 0.060152071063758236
3.0 -2.0 0.055896322663934475
3.0 -1.5 0.05234476893863641
3.0 -1.0 0.049544636313092284
3.0 -0.5 0.047576436099791994
3.0 0.0 0.046423209361578885
3.0 0.5 0.04610274027540527
3.0 1.0 0.046618399477304395
3.0 1.5 0.04828281308781417
3.0 2.0 0.05186910470393694
3.0 2.5 0.056846749553816654
3.0 3.0 0.06259397058924107
3.0 3.5 0.06903481251880603
3.0 4.0 0.0761652236117206
3.0 4.5 0.08401756966669177
3.0 5.0 0.09317687503653527
3.0 5.5 0.10373439212118268
3.0 6.0 0.11510331101922414
3.5 -6.0 0.12586765073941983
3.5 -5.5 0.114251911400146
3.5 -5.0 0.10375586158811524
3.5 -4.5 0.09424839206475218
3.5 -4.0 0.0856460313264866
3.5 -3.5 0.07887422394334533
3.5 -3.0 0.07320314672523548
3.5 -2.5 0.06831459995547025
3.5 -2.0 0.06414247002434183
3.5 -1.5 0.060682637536998325
3.5 -1.0 0.058005613874087134
3.5 -0.5 0.056089335353022345
3.5 0.0 0.054938809628469094
3.5 0.5 0.0545603400236789
3.5 1.0 0.054957015043118645
3.5 1.5 0.05634221756352602
3.5 2.0 0.059048323112588286
3.5 2.5 0.06394206950136841
3.5 3.0 0.06964070915367568
3.5 3.5 0.07606230347898446
3.5 4.0 0.08320232624567234
3.5 4.5 0.09105946386467621
3.5 5.0 0.09966494963799083
3.5 5.5 0.10903428615787655
3.5 6.0 0.12031285997876685
4.0 -6.0 0.133792145149595
4.0 -5.5 0.12206499479627937
4.0 -5.0 0.11146700114689294
4.0 -4.5 0.10186454074602272
4.0 -4.0 0.09418377264877643
4.0 -3.5 0.08772176543516065
4.0 -3.0 0.0820764047743747
4.0 -2.5 0.0772077219594533
4.0 -2.0 0.07308024982411171
4.0 -1.5 0.06971025700759262
4.0 -1.0 0.06710202328253884
4.0 -0.5 0.06522712879652033
4.0 0.0 0.06407790117733198
4.0 0.5 0.06365266208275742
4.0 1.0 0.06395570593307875
4.0 1.5 0.06506960381759554
4.0 2.0 0.06747175914215608
4.0 2.5 0.07174258558181792
4.0 3.0 0.07743800200878338
4.0 3.5 0.08388735586865755
4.0 4.0 0.09108728791092392
4.0 4.5 0.09903205128087511
4.0 5.0 0.10770701935671877
4.0 5.5 0.1171179095976792
4.0 6.0 0.12725508680895073
4.5 -6.0 0.14251731518187546
4.5 -5.5 0.13079234359397504
4.5 -5.0 0.1200802600050456
4.5 -4.5 0.11131656818936357
4.5 -4.0 0.10392224116797841
4.5 -3.5 0.09738476235299591
4.5 -3.0 0.09170467242634588
4.5 -2.5 0.0868217625184239
4.5 -2.0 0.08272226723731291
4.5 -1.5 0.07942072306568614
4.5 -1.0 0.07686471203463068
4.5 -0.5 0.07502497903263568
4.5 0.0 0.07387957119589768
4.5 0.5 0.07341940505336114
4.5 1.0 0.07365045362088911
4.5 1.5 0.07459081032641238
4.5 2.0 0.07685985632305131
4.5 2.5 0.08031780123563345
4.5 3.0 0.08603239012387602
4.5 3.5 0.09256516535112001
4.5 4.0 0.09988876236789454
4.5 4.5 0.1080020405330592
4.5 5.0 0.11688310817824318
4.5 5.5 0.12645920459164933
4.5 6.0 0.1366322315647201
5.0 -6.0 0.1523328637892237
5.0 -5.5 0.14054781587690227
5.0 -5.0 0.13052983233669407
5.0 -4.5 0.12205039554787647
5.0 -4.0 0.11448046730582813
5.0 -3.5 0.10783138431853664
5.0 -3.0 0.10206619066117782
5.0 -2.5 0.09714667576214403
5.0 -2.0 0.0930850481909242
5.0 -1.5 0.08982914644494729
5.0 -1.0 0.08732702796352815
5.0 -0.5 0.08552973825002326
5.0 0.0 0.0843991220385463
5.0 0.5 0.0839176211800932
5.0 1.0 0.08409340126249273
5.0 1.5 0.08495785377584197
5.0 2.0 0.08703996997807417
5.0 2.5 0.09011891102447459
5.0 3.0 0.09547365519239712
5.0 3.5 0.10215016621575546
5.0 4.0 0.10966196205611348
5.0 4.5 0.1180304927623302
5.0 5.0 0.12726703636773867
5.0 5.5 0.1372865050327117
5.0 6.0 0.1478064919610664
5.5 -6.0 0.1636053552487786
5.5 -5.5 0.15212475561909347
5.5 -5.0 0.14235249659702867
5.5 -4.5 0.1335735300779554
5.5 -4.0 0.12579513686101415
5.5 -3.5 0.11900223921967643
5.5 -3.0 0.11313449935457229
5.5 -2.5 0.10819010219770432
5.5 -2.0 0.10414956170413354
5.5 -1.5 0.10094948589717258
5.5 -1.0 0.09851922230349994
5.5 -0.5 0.09678557585564584
5.5 0.0 0.09568989337692183
5.5 0.5 0.09520311161344956
5.5 1.0 0.09533527528740036
5.5 1.5 0.0961354364384711
5.5 2.0 0.09804994539264066
5.5 2.5 0.1011788782487751
5.5 3.0 0.10584208413312782
5.5 3.5 0.11270085054290253
5.5 4.0 0.12044861656558571
5.5 4.5 0.1291132018413605
5.5 5.0 0.13881885187727533
5.5 5.5 0.14960729922078633
5.5 6.0 0.1611476715258596
6.0 -6.0 0.17654735317050663
6.0 -5.5 0.16505669257793532
6.0 -5.0 0.15479188392548418
6.0 -4.5 0.14574728158590441
6.0 -4.0 0.1377961837178277
6.0 -3.5 0.13085674447548182
6.0 -3.0 0.12488846636273106
6.0 -2.5 0.11991653949418705
6.0 -2.0 0.11590576275041145
6.0 -1.5 0.11278784211279848
6.0 -1.0 0.11046405727610159
6.0 -0.5 0.10882988890631616
6.0 0.0 0.10779986009578621
6.0 0.5 0.10732790503326602
6.0 1.0 0.1074228254884247
6.0 1.5 0.10815528544853145
6.0 2.0 0.10991460554177046
6.0 2.5 0.11313217510665137
6.0 3.0 0.11728859913249637
6.0 3.5 0.12429781029700211
6.0 4.0 0.13231121829971745
6.0 4.5 0.14119256704814415
6.0 5.0 0.15126415998247217
6.0 5.5 0.16297208655716253
6.0 6.0 0.17623285734016597
"""))
saveplot(plt,"trussCenter")
```
\textoutput{truss_center}

To make the example more interesting (and to enlarge the range of
variation of the objective function), we decided to also apply an
horizontal force to the truss' nodes, changing the objective function's
landscape:

```julia:truss_offset
#hideall
plt = plot_2d(bench_data("""
X Y MaxDisplacement
-6.0 -6.0 3.280240406125791
-6.0 -5.5 2.9691762278004514
-6.0 -5.0 2.666919633307022
-6.0 -4.5 2.3737414101669834
-6.0 -4.0 2.089920904560191
-6.0 -3.5 1.8157329515195715
-6.0 -3.0 1.551439981405726
-6.0 -2.5 1.2972981116428763
-6.0 -2.0 1.053587908197901
-6.0 -1.5 0.8206957506080172
-6.0 -1.0 0.6021532188349097
-6.0 -0.5 0.40709433920737514
-6.0 0.0 0.24351638372589246
-6.0 0.5 0.29342088163104774
-6.0 1.0 0.4760946921181181
-6.0 1.5 0.692734066733828
-6.0 2.0 0.917662941622969
-6.0 2.5 1.1455693797021294
-6.0 3.0 1.3747014791976653
-6.0 3.5 1.6043592553743338
-6.0 4.0 1.8342029958091857
-6.0 4.5 2.064004178098286
-6.0 5.0 2.2935668101309448
-6.0 5.5 2.522776507121736
-6.0 6.0 2.751619813824027
-5.5 -6.0 3.2766959603004064
-5.5 -5.5 2.9651539147590595
-5.5 -5.0 2.6625576654457186
-5.5 -4.5 2.369212751131049
-5.5 -4.0 2.085407415697921
-5.5 -3.5 1.81141830751969
-5.5 -3.0 1.5475130748266153
-5.5 -2.5 1.2939595803693587
-5.5 -2.0 1.05105324942714
-5.5 -1.5 0.8191899451399706
-5.5 -1.0 0.6025854081326557
-5.5 -0.5 0.408677937133637
-5.5 0.0 0.24506364203581743
-5.5 0.5 0.2959121192195627
-5.5 1.0 0.46976969954126135
-5.5 1.5 0.6822341567932866
-5.5 2.0 0.9030829400848848
-5.5 2.5 1.126964805223051
-5.5 3.0 1.3521166464121086
-5.5 3.5 1.577847789984069
-5.5 4.0 1.8038565662288872
-5.5 4.5 2.0300046297525887
-5.5 5.0 2.256259716916201
-5.5 5.5 2.482720336190461
-5.5 6.0 2.7095983348115507
-5.0 -6.0 3.2713799277010795
-5.0 -5.5 2.9599341443203984
-5.0 -5.0 2.6573809846739307
-5.0 -4.5 2.3641325460203757
-5.0 -4.0 2.0805302460784807
-5.0 -3.5 1.8068804418000786
-5.0 -3.0 1.5434718818945212
-5.0 -2.5 1.2905912889145477
-5.0 -2.0 1.0485510824871747
-5.0 -1.5 0.8177573462513495
-5.0 -1.0 0.6030504167096572
-5.0 -0.5 0.41057490129985075
-5.0 0.0 0.2469090498383643
-5.0 0.5 0.29846931237404656
-5.0 1.0 0.46316714962512673
-5.0 1.5 0.6713115585016198
-5.0 2.0 0.8879441816458585
-5.0 2.5 1.1076792007087568
-5.0 3.0 1.3287492017040317
-5.0 3.5 1.5504818788816064
-5.0 4.0 1.7726180614953275
-5.0 4.5 1.9950902283134304
-5.0 5.0 2.2179574004129483
-5.0 5.5 2.441399686893275
-5.0 6.0 2.680129797081917
-4.5 -6.0 3.2648529319023267
-4.5 -5.5 2.953785569279526
-4.5 -5.0 2.651534957054542
-4.5 -4.5 2.3585937153332046
-4.5 -4.0 2.075359809771146
-4.5 -3.5 1.8021785222449387
-4.5 -3.0 1.5393675311662263
-4.5 -2.5 1.2872373465897196
-4.5 -2.0 1.0461196970607685
-4.5 -1.5 0.8164322570164987
-4.5 -1.0 0.6035957898861563
-4.5 -0.5 0.41276180541644175
-4.5 0.0 0.24901583553277562
-4.5 0.5 0.3011394410571958
-4.5 1.0 0.4641359879502224
-4.5 1.5 0.6599955191844358
-4.5 2.0 0.8722807260801484
-4.5 2.5 1.0877555969319694
-4.5 3.0 1.3046517554553418
-4.5 3.5 1.5223175217628748
-4.5 4.0 1.7405315155832737
-4.5 4.5 1.9592764987753934
-4.5 5.0 2.1786614616809006
-4.5 5.5 2.424609492418035
-4.5 6.0 2.681920163846265
-4.0 -6.0 3.2576861249077487
-4.0 -5.5 2.9470544514069026
-4.0 -5.0 2.6452350363957735
-4.0 -4.5 2.352739986091921
-4.0 -4.0 2.0700006492414342
-4.0 -3.5 1.7973944792716696
-4.0 -3.0 1.5352674151942542
-4.0 -2.5 1.2839544044404976
-4.0 -2.0 1.0438076385950872
-4.0 -1.5 0.8152571502345679
-4.0 -1.0 0.6042722332152773
-4.0 -0.5 0.41523715642882336
-4.0 0.0 0.25137194357368403
-4.0 0.5 0.30396498225831514
-4.0 1.0 0.46640173136811447
-4.0 1.5 0.6483153634121375
-4.0 2.0 0.856122512259547
-4.0 2.5 1.067226156120669
-4.0 3.0 1.2798569882168682
-4.0 3.5 1.4933822411689075
-4.0 4.0 1.7076114001321356
-4.0 4.5 1.931310688135417
-4.0 5.0 2.175237649179227
-4.0 5.5 2.4262766217546905
-4.0 6.0 2.684153141797731
-3.5 -6.0 3.2502237464947785
-3.5 -5.5 2.940021242808576
-3.5 -5.0 2.6386903683561447
-3.5 -4.5 2.346726465534524
-3.5 -4.0 2.0645711209999593
-3.5 -3.5 1.7926220753413904
-3.5 -3.0 1.5312481786766767
-3.5 -2.5 1.2808068326464817
-3.5 -2.0 1.0416699454429923
-3.5 -1.5 0.8142799071390044
-3.5 -1.0 0.6051327169977736
-3.5 -0.5 0.41801443219050854
-3.5 0.0 0.253982339782518
-3.5 0.5 0.3069839631317403
-3.5 1.0 0.4689403707429824
-3.5 1.5 0.6421438754117815
-3.5 2.0 0.8394927166977816
-3.5 2.5 1.0461120409107096
-3.5 3.0 1.2543824031832376
-3.5 3.5 1.4670450686174437
-3.5 4.0 1.6960073956179063
-3.5 4.5 1.9327640344526555
-3.5 5.0 2.17700728219752
-3.5 5.5 2.4284469969654974
-3.5 6.0 2.686800128017926
-3.0 -6.0 3.24262257186628
-3.0 -5.5 2.932866879078714
-3.0 -5.0 2.6320659942846945
-3.0 -4.5 2.3406921362945883
-3.0 -4.0 2.0591857640774913
-3.0 -3.5 1.787956018234305
-3.0 -3.0 1.5273891608762176
-3.0 -2.5 1.277862038912268
-3.0 -2.0 1.039764760673138
-3.0 -1.5 0.813551349195087
-3.0 -1.0 0.60623135757977
-3.0 -0.5 0.4211169724782567
-3.0 0.0 0.2568639269271454
-3.0 0.5 0.3102309684345628
-3.0 1.0 0.47178682915722736
-3.0 1.5 0.6445822145697464
-3.0 2.0 0.8322922120249036
-3.0 2.5 1.0356017556377999
-3.0 3.0 1.2478942917576556
-3.0 3.5 1.4687651901448588
-3.0 4.0 1.6978454710764879
-3.0 4.5 1.9347954126098463
-3.0 5.0 2.1792986205081464
-3.0 5.5 2.431054575443392
-3.0 6.0 2.689770901012013
-2.5 -6.0 3.2349481616710243
-2.5 -5.5 2.925699431928863
-2.5 -5.0 2.6254810782092997
-2.5 -4.5 2.334750577168581
-2.5 -4.0 2.053946257606835
-2.5 -3.5 1.7834850799704627
-2.5 -3.0 1.5237673871537238
-2.5 -2.5 1.2751870794361961
-2.5 -2.0 1.0381509021851685
-2.5 -1.5 0.8131234756288034
-2.5 -1.0 0.6076225492691177
-2.5 -0.5 0.42457444524572363
-2.5 0.0 0.2600422905026241
-2.5 0.5 0.3137385451534751
-2.5 1.0 0.47497202595634014
-2.5 1.5 0.6474379718528033
-2.5 2.0 0.8346401256069325
-2.5 2.5 1.037870396271867
-2.5 3.0 1.250151793323654
-2.5 3.5 1.471075309602326
-2.5 4.0 1.7002653401149226
-2.5 4.5 1.9373736421250154
-2.5 5.0 2.1820730591091273
-2.5 5.5 2.4340498004360818
-2.5 6.0 2.6929949761416108
-2.0 -6.0 3.2272390633677945
-2.0 -5.5 2.9185901258538918
-2.0 -5.0 2.619023532834992
-2.0 -4.5 2.3289935216912037
-2.0 -4.0 2.0489405989552685
-2.0 -3.5 1.7792901320148162
-2.0 -3.0 1.5204557166604222
-2.0 -2.5 1.2728471571654456
-2.0 -2.0 1.0368867258532004
-2.0 -1.5 0.8130486135186232
-2.0 -1.0 0.6093605641854403
-2.0 -0.5 0.42842061221786426
-2.0 0.0 0.263549695800665
-2.0 0.5 0.3175386320576312
-2.0 1.0 0.47852527505483633
-2.0 1.5 0.6507367074750093
-2.0 2.0 0.8374829602295727
-2.0 2.5 1.040682749869582
-2.0 3.0 1.25298352174251
-2.0 3.5 1.473969717008298
-2.0 4.0 1.7032570512514698
-2.0 4.5 1.940486841988562
-2.0 5.0 2.185319152066068
-2.0 5.5 2.4374239086929985
-2.0 6.0 2.696470010129084
-1.5 -6.0 3.2195378747579424
-1.5 -5.5 2.911599645211625
-1.5 -5.0 2.6127666589930754
-1.5 -4.5 2.3234996745481746
-1.5 -4.0 2.0442472093437436
-1.5 -3.5 1.7754458688187489
-1.5 -3.0 1.5175235129458673
-1.5 -2.5 1.2709058675481488
-1.5 -2.0 1.0360302001450694
-1.5 -1.5 0.8133794144543646
-1.5 -1.0 0.6122476464520931
-1.5 -0.5 0.43269210747446146
-1.5 0.0 0.26742391129321424
-1.5 0.5 0.321663810033142
-1.5 1.0 0.4824762679877439
-1.5 1.5 0.654504738338219
-1.5 2.0 0.8408364915544877
-1.5 2.5 1.0440499624041732
-1.5 3.0 1.256396760044088
-1.5 3.5 1.4774534256115923
-1.5 4.0 1.706825870164317
-1.5 4.5 1.9441440770182683
-1.5 5.0 2.1890547252043238
-1.5 5.5 2.4412112641683144
-1.5 6.0 2.7002613215899376
-1.0 -6.0 3.2119037684739036
-1.0 -5.5 2.9047934748617448
-1.0 -5.0 2.6067819611872514
-1.0 -4.5 2.318343650497515
-1.0 -4.0 2.0399406069450734
-1.0 -3.5 1.772024277951578
-1.0 -3.0 1.515038778155525
-1.0 -2.5 1.2694265482898268
-1.0 -2.0 1.0356397780916071
-1.0 -1.5 0.8141694140814042
-1.0 -1.0 0.617341253829252
-1.0 -0.5 0.4374279380632287
-1.0 0.0 0.2717075479478582
-1.0 0.5 0.3261482869067049
-1.0 1.0 0.48685654136489953
-1.0 1.5 0.6587709859501543
-1.0 2.0 0.8447204452122187
-1.0 2.5 1.0479890043010724
-1.0 3.0 1.260406950861574
-1.0 3.5 1.4815423169224686
-1.0 4.0 1.7109909812089437
-1.0 4.5 1.9483718606346654
-1.0 5.0 2.19331941975585
-1.0 5.5 2.4454735488748995
-1.0 6.0 2.704467187002476
-0.5 -6.0 3.2127615773010705
-0.5 -5.5 2.9045237361738976
-0.5 -5.0 2.6055781755947622
-0.5 -4.5 2.3164482288394366
-0.5 -4.0 2.037644783085809
-0.5 -3.5 1.769667401200569
-0.5 -3.0 1.5130705545234142
-0.5 -2.5 1.268473916304102
-0.5 -2.0 1.035775501712454
-0.5 -1.5 0.8171430090126126
-0.5 -1.0 0.6230062380814733
-0.5 -0.5 0.4426694225067538
-0.5 0.0 0.27646675889641126
-0.5 0.5 0.3310285972969471
-0.5 1.0 0.4917004241925889
-0.5 1.5 0.6635680558683072
-0.5 2.0 0.8491593607499063
-0.5 2.5 1.052523179090125
-0.5 3.0 1.2650374759454175
-0.5 3.5 1.4862617134483005
-0.5 4.0 1.7157821730083078
-0.5 4.5 1.9532078004624682
-0.5 5.0 2.1981631235639467
-0.5 5.5 2.450278858286889
-0.5 6.0 2.7091812786817315
0.0 -6.0 3.2214698398087473
0.0 -5.5 2.9133784171450903
0.0 -5.0 2.614447536282122
0.0 -4.5 2.32522254838408
0.0 -4.0 2.0462349753163815
0.0 -3.5 1.7780043505470506
0.0 -3.0 1.5210390604691488
0.0 -2.5 1.2758354074408085
0.0 -2.0 1.042874257726227
0.0 -1.5 0.8239115760255369
0.0 -1.0 0.6292811354037965
0.0 -0.5 0.44846030228748385
0.0 0.0 0.2817606545715172
0.0 0.5 0.33634402773642685
0.0 1.0 0.4970455004932857
0.0 1.5 0.6689326391563248
0.0 2.0 0.8541826560331034
0.0 2.5 1.057681748911487
0.0 3.0 1.2703185580840894
0.0 3.5 1.4916441840282784
0.0 4.0 1.721236020198237
0.0 4.5 1.95869435928487
0.0 5.0 2.20363613197402
0.0 5.5 2.4556868272478005
0.0 6.0 2.7144721793312607
0.5 -6.0 3.2306062271948655
0.5 -5.5 2.922758174513151
0.5 -5.0 2.623918777141002
0.5 -4.5 2.334656415068708
0.5 -4.0 2.0555246025863525
0.5 -3.5 1.7870644335740113
0.5 -3.0 1.5298053158149758
0.5 -2.5 1.2842636081127314
0.5 -2.0 1.0509387998556405
0.5 -1.5 0.8313784886236734
0.5 -1.0 0.6362060772297977
0.5 -0.5 0.4548467902405652
0.5 0.0 0.2876115469754075
0.5 0.5 0.34213678619270566
0.5 1.0 0.5029326338128111
0.5 1.5 0.6749053247068734
0.5 2.0 0.8598240173263454
0.5 2.5 1.063498896466607
0.5 3.0 1.2762856621705634
0.5 3.5 1.4977272364420922
0.5 4.0 1.727392705759442
0.5 4.5 1.96487466498092
0.5 5.0 2.209783999848195
0.5 5.5 2.4617433572897403
0.5 6.0 2.7203810777015414
1.0 -6.0 3.2402282979192987
1.0 -5.5 2.9327072584895753
1.0 -5.0 2.634029413417667
1.0 -4.5 2.3447842101984993
1.0 -4.0 2.065546799376445
1.0 -3.5 1.796880589671882
1.0 -3.0 1.5393371311373556
1.0 -2.5 1.2934538079640432
1.0 -2.0 1.0597494291969043
1.0 -1.5 0.8395802872581747
1.0 -1.0 0.6438227251648225
1.0 -0.5 0.46187735552889536
1.0 0.0 0.2940774350912065
1.0 0.5 0.34851083406813915
1.0 1.0 0.5094056011785713
1.0 1.5 0.6815298977490507
1.0 2.0 0.8661202077342125
1.0 2.5 1.070012154740237
1.0 3.0 1.2829775827587682
1.0 3.5 1.5045511676653764
1.0 4.0 1.7342938494272988
1.0 4.5 1.97179072741534
1.0 5.0 2.2166469457197153
1.0 5.5 2.4684828043768086
1.0 6.0 2.726929819516542
1.5 -6.0 3.2503831430699943
1.5 -5.5 2.943264861555791
1.5 -5.0 2.6448156957807587
1.5 -4.5 2.355640905971408
1.5 -4.0 2.0763358631220035
1.5 -3.5 1.8074868915822409
1.5 -3.0 1.5496689021674563
1.5 -2.5 1.3034413964248308
1.5 -2.0 1.0693433259353637
1.5 -1.5 0.8485538755961168
1.5 -1.0 0.6521736390922366
1.5 -0.5 0.4696020841490904
1.5 0.0 0.30121858198192825
1.5 0.5 0.3555686595385146
1.5 1.0 0.5165103864586471
1.5 1.5 0.6888521898328044
1.5 2.0 0.8779995393859337
1.5 2.5 1.0827410379499434
1.5 3.0 1.2960693706497557
1.5 3.5 1.5174830988459258
1.5 4.0 1.7465438658566923
1.5 4.5 1.9828537623810234
1.5 5.0 2.2260434516235197
1.5 5.5 2.4759338489350022
1.5 6.0 2.734132019065219
2.0 -6.0 3.261092717785366
2.0 -5.5 2.9544590069835563
2.0 -5.0 2.6563097139452223
2.0 -4.5 2.3672599768286404
2.0 -4.0 2.0879251785835407
2.0 -3.5 1.8189163778940391
2.0 -3.0 1.5608338160500799
2.0 -2.5 1.3142604617336788
2.0 -2.0 1.0797567131300179
2.0 -1.5 0.8583349717497194
2.0 -1.0 0.6613009671547216
2.0 -0.5 0.4780714937419477
2.0 0.0 0.3090961624621106
2.0 0.5 0.363264377287931
2.0 1.0 0.5242941894581815
2.0 1.5 0.6969185469386872
2.0 2.0 0.890819292635058
2.0 2.5 1.0971030291137776
2.0 3.0 1.31184674443812
2.0 3.5 1.5345301534380618
2.0 4.0 1.7647035644846552
2.0 4.5 2.001960651960973
2.0 5.0 2.2459250960564114
2.0 5.5 2.49624459035316
2.0 6.0 2.752591601446756
2.5 -6.0 3.272351086555648
2.5 -5.5 2.966308242511369
2.5 -5.0 2.668540026938044
2.5 -4.5 2.379672043580192
2.5 -4.0 2.1003444654154473
2.5 -3.5 1.831197671700285
2.5 -3.0 1.5728603913351278
2.5 -2.5 1.3259410827783278
2.5 -2.0 1.0910220269454554
2.5 -1.5 0.8689557016692327
2.5 -1.0 0.6712444085968454
2.5 -0.5 0.4873347193765945
2.5 0.0 0.31811080772838624
2.5 0.5 0.3716501357737926
2.5 1.0 0.5328042125776948
2.5 1.5 0.7057739921383198
2.5 2.0 0.9042801204495905
2.5 2.5 1.1121141151013938
2.5 3.0 1.3282778777339543
2.5 3.5 1.552229902344862
2.5 4.0 1.7835073124765783
2.5 4.5 2.0216929983969956
2.5 5.0 2.2663996655990486
2.5 5.5 2.517263443044007
2.5 6.0 2.773947667835753
3.0 -6.0 3.2841481729201476
3.0 -5.5 2.97883453678867
3.0 -5.0 2.681535278057233
3.0 -4.5 2.3929029513578017
3.0 -4.0 2.1136155093563387
3.0 -3.5 1.844350045497559
3.0 -3.0 1.5857676881588545
3.0 -2.5 1.3385039689259535
3.0 -2.0 1.1031641388281612
3.0 -1.5 0.8804413995057173
3.0 -1.0 0.682038455453149
3.0 -0.5 0.49743701972885757
3.0 0.0 0.3285170929966596
3.0 0.5 0.38077894517853256
3.0 1.0 0.5420862758202636
3.0 1.5 0.7179550560388934
3.0 2.0 0.9183923465897285
3.0 2.5 1.127775063365131
3.0 3.0 1.3453557466074757
3.0 3.5 1.570569080957711
3.0 4.0 1.8029376553102738
3.0 4.5 2.042032194509772
3.0 5.0 2.2874513411602626
3.0 5.5 2.538812390187521
3.0 6.0 2.7957563072433746
3.5 -6.0 3.2965188278565147
3.5 -5.5 2.992079761762674
3.5 -5.0 2.695324229914686
3.5 -4.5 2.4069679533781905
3.5 -4.0 2.127744755285934
3.5 -3.5 1.8583765766418703
3.5 -3.0 1.599559374586305
3.5 -2.5 1.351956367474888
3.5 -2.0 1.1161959049129675
3.5 -1.5 0.8928765258590683
3.5 -1.0 0.6937089656242361
3.5 -0.5 0.5084165755358484
3.5 0.0 0.3397513103066822
3.5 0.5 0.39070385641389516
3.5 1.0 0.5521832618133999
3.5 1.5 0.7311091163022223
3.5 2.0 0.9331610858242473
3.5 2.5 1.1440802436247803
3.5 3.0 1.3630652816027249
3.5 3.5 1.5895245646968015
3.5 4.0 1.822965428935801
3.5 4.5 2.062947153469268
3.5 5.0 2.3090548100111716
3.5 5.5 2.5608825239859265
3.5 6.0 2.8180327108928003
4.0 -6.0 3.309580032146962
4.0 -5.5 3.0061016514184016
4.0 -5.0 2.7099198887708758
4.0 -4.5 2.4218557916230767
4.0 -4.0 2.1427118961405185
4.0 -3.5 1.8732559661636403
4.0 -3.0 1.614217505610666
4.0 -2.5 1.3662863527714844
4.0 -2.0 1.130113521103199
4.0 -1.5 0.9063207717458814
4.0 -1.0 0.7062691488456891
4.0 -0.5 0.5203005551907874
4.0 0.0 0.3583674454615448
4.0 0.5 0.4014768851730555
4.0 1.0 0.5631332839174654
4.0 1.5 0.7449504344363203
4.0 2.0 0.9485843205151244
4.0 2.5 1.1610148268111515
4.0 3.0 1.3813805340761198
4.0 3.5 1.609059936963071
4.0 4.0 1.8435440131609675
4.0 4.5 2.084383614596613
4.0 5.0 2.331157877897805
4.0 5.5 2.5834447662393543
4.0 6.0 2.8407997398142317
4.5 -6.0 3.3234855763505498
4.5 -5.5 3.0209169270652065
4.5 -5.0 2.7252780329481836
4.5 -4.5 2.4375052704952624
4.5 -4.0 2.1584572760883582
4.5 -3.5 1.8889357614561482
4.5 -3.0 1.629697940834148
4.5 -2.5 1.3814588340659293
4.5 -2.0 1.1448923485330305
4.5 -1.5 0.9206441000012615
4.5 -1.0 0.7197150440165642
4.5 -0.5 0.5331003934171796
4.5 0.0 0.3784269760083542
4.5 0.5 0.41314741754804835
4.5 1.0 0.5749673098898026
4.5 1.5 0.7594834361230043
4.5 2.0 0.9646489113296812
4.5 2.5 1.1785512806762808
4.5 3.0 1.4002620558939338
4.5 3.5 1.6291237430939771
4.5 4.0 1.8646061211958282
4.5 4.5 2.1062538692256494
4.5 5.0 2.353656721038332
4.5 5.5 2.6064077432870114
4.5 6.0 2.8640441132586836
5.0 -6.0 3.3382269368835407
5.0 -5.5 3.0363814817743044
5.0 -5.0 2.7412410205403317
5.0 -4.5 2.4537844418299284
5.0 -4.0 2.174877095055518
5.0 -3.5 1.9053321883970287
5.0 -3.0 1.6459300757010762
5.0 -2.5 1.3974138857292546
5.0 -2.0 1.1604838939337716
5.0 -1.5 0.9358112830253906
5.0 -1.0 0.7340205318100115
5.0 -0.5 0.5468061624745916
5.0 0.0 0.3999696181039931
5.0 0.5 0.4271471278537288
5.0 1.0 0.5877058423054323
5.0 1.5 0.774699571920353
5.0 2.0 0.9813250897057986
5.0 2.5 1.1966437030979022
5.0 3.0 1.4196534295006018
5.0 3.5 1.6496503181257114
5.0 4.0 1.8860680466192212
5.0 4.5 2.1284368168432626
5.0 5.0 2.3763762548135903
5.0 5.5 2.6295600449332257
5.0 6.0 2.8876180331442396
5.5 -6.0 3.3533047898274133
5.5 -5.5 3.052075110359471
5.5 -5.0 2.757515845445716
5.5 -4.5 2.4705011475213627
5.5 -4.0 2.1918393451129923
5.5 -3.5 1.9223417949039439
5.5 -3.0 1.6628226410754217
5.5 -2.5 1.4140681382646871
5.5 -2.0 1.176814392518188
5.5 -1.5 0.9517609560640681
5.5 -1.0 0.7491319367507839
5.5 -0.5 0.5613798310595735
5.5 0.0 0.4230482407345408
5.5 0.5 0.44622527093297965
5.5 1.0 0.6013543730831169
5.5 1.5 0.7905711921793726
5.5 2.0 0.9985576355362733
5.5 2.5 1.2158411534332003
5.5 3.0 1.4404491523860956
5.5 3.5 1.670560782418027
5.5 4.0 1.9078452723097137
5.5 4.5 2.150804082170979
5.5 5.0 2.3990877500134253
5.5 5.5 2.6525482266531792
5.5 6.0 2.9111327591458287
6.0 -6.0 3.367626875335638
6.0 -5.5 3.067364553442861
6.0 -5.0 2.773757571188218
6.0 -4.5 2.4906819312079884
6.0 -4.0 2.2173340218961934
6.0 -3.5 1.9542118174120708
6.0 -3.0 1.6954749658661854
6.0 -2.5 1.4422285426248598
6.0 -2.0 1.199447924509244
6.0 -1.5 0.9697249833538801
6.0 -1.0 0.7649625702061827
6.0 -0.5 0.5767472057998081
6.0 0.0 0.4476961366019809
6.0 0.5 0.46664752421194755
6.0 1.0 0.621557224806606
6.0 1.5 0.808113213838698
6.0 2.0 1.0200048629972338
6.0 2.5 1.2408469991377995
6.0 3.0 1.4678569430630655
6.0 3.5 1.6995949261961305
6.0 4.0 1.935137596280732
6.0 4.5 2.1737941813580006
6.0 5.0 2.4216052667017363
6.0 5.5 2.6750064534273856
6.0 6.0 2.9341403073927084
"""))
saveplot(plt,"trussOffset")
```
\textoutput{truss_offset}

Given that we were interested in evaluating the scalability of the
optimization as the number of CPUs increases, we selected optimization
algorithms that we knew were already parallelized. A suitable
candidade is BlackBoxOptim, a parallelized optimization package
supporting both multi- and single-objective optimization problems
using meta-heuristics algorithms.

BlackBoxOptim supports both multi-threaded and parallel execution,
allowing the optimization algorithm to evaluate many candidate
solutions at the same time. Given that Khepri is not yet thread-safe,
we opted for parallel evaluation using multiple independent processes.
Following the BlackBoxOptim guidelines, we used the following
template:

```julia
using Distributed
using Random

addprocs(parse(Int, ARGS[1])-1)
@everywhere include("RandomDomeTruss.jl")
@everywhere using BlackBoxOptim

Random.seed!(12345)

opt = bbsetup(displacement,
        Method=:xnes,
        SearchRange = [(-6.0, 6.0), (-6.0, 6.0)],
        MaxFuncEvals = 1000,
        Workers = workers())

res = bboptimize(opt)

println("Solution candidate:", best_candidate(res))
println("Solution fitness:", best_fitness(res))
```

Given that the master process is responsible for running the
optimization algorithm and the workers are only responsible for
evaluating candidate solutions, we fixed the seed of the master's
random number generator so that we could repeat the experiments with a
different number of workers but without changing the sequence of steps
taken. This ensures that the optimization always finds the same
solution after the same number of steps.

Note that BlackBoxOptim requires, first, that we setup the
optimization problem, using the `bbsetup` function. Here, the
`displacement` argument is the function to minimize. It measures the
maximum displacement of a truss' node. The next argument specifies the
optimization method to use, in this case, we selected the Exponential
Natural Evolution Strategy (xNES). Then, we specify the domain of the
two variables $x$ and $y$ representing the projection on the $XY$
plane of the point where all the truss' arcs join. Note that this is a
square that fits inside the slab that supports the truss. We also
specify the maximum number of objective function evaluations and the
set of workers that will be used to compute those evaluations.

After the setup, the function `bboptimize` does the job of
coordinating the workers, assigning them candidate solutions to
evaluate, collecting the results and deciding the evolution of the set
of candidates.

As before, we tested the script using an increasing number of workers
and we did three independent runs to smooth out the noise. We allowed
the optimization to do a maximum number of objective function
evaluations of 1000. In all cases, the solution found was the same, as
expected from the fixed random seed used that forced the optimization
to be deterministic. The following table presents the mean time spent
in the optimization process for different numbers of processes. Again,
note that the number of workers is one less than the number of
processes.

```julia:plotopt1
#hideall
#opt = bbsetup(displacement_obj; Method=:xnes, SearchRange = [(-6.0, 6.0), (-6.0, 6.0)], MaxFuncEvals = 1000, Workers = workers())

opt_xnes = bench_data("""
Processes StopTime Steps_per_second Evals_per_second OptTime RealTime UserTime SysTime
2 26833.04 0.01 0.04 26838.224 447m49.938s 0m31.358s 0m0.457s
4 13317.67 0.02 0.08 13323.388 222m35.464s 0m31.426s 0m0.422s
8 6781.98 0.04 0.15 6788.712 113m44.461s 0m31.954s 0m0.561s
16 6765.22 0.04 0.15 6773.607 113m28.715s 447m54.407s 0m38.400s
32 6714.40 0.04 0.15 6727.071 112m43.982s 0m31.895s 0m0.517s
48 6640.26 0.04 0.15 6657.509 111m38.424s 0m31.228s 0m0.886s
64 6740.63 0.04 0.15 6761.836 113m23.802s 229m11.795s 1m0.496s
80 6756.99 0.04 0.15 6782.62 113m49.160s 0m32.236s 0m1.031s
96 6635.27 0.04 0.15 6665.09 111m54.052s 0m32.493s 0m0.866s
2 26755.25 0.01 0.04 26760.192 446m32.486s 0m31.680s 0m0.419s
4 13274.71 0.02 0.08 13280.038 221m53.130s 154m29.379s 0m14.096s
8 6844.90 0.04 0.15 6851.566 114m45.113s 334m22.435s 0m26.500s
16 6722.62 0.04 0.15 6731.171 112m49.012s 1m38.713s 0m5.266s
32 6705.68 0.04 0.15 6718.478 112m36.428s 0m32.141s 0m0.578s
48 6710.32 0.04 0.15 6727.487 112m48.958s 0m31.598s 0m0.839s
64 6795.03 0.04 0.15 6816.605 114m19.968s 6m37.853s 0m36.368s
80 6726.75 0.04 0.15 6753.048 113m19.512s 0m33.015s 0m0.756s
96 6634.48 0.04 0.15 6664.732 111m52.357s 0m32.479s 0m0.792s
2 26755.23 0.01 0.04 26760.215 446m31.747s 0m31.197s 0m0.409s
4 13256.53 0.02 0.08 13261.939 221m34.096s 0m31.289s 0m0.385s
8 6706.34 0.04 0.15 6712.648 112m25.434s 442m33.363s 0m41.845s
16 6642.89 0.04 0.15 6651.758 111m29.050s 0m32.435s 0m0.757s
32 6739.13 0.04 0.15 6751.755 113m9.908s 0m32.003s 0m0.652s
48 6716.19 0.04 0.15 6733.753 112m56.609s 0m32.974s 0m0.875s
64 6830.02 0.04 0.15 6852.656 114m56.796s 5m4.119s 0m31.796s
80 6731.74 0.04 0.15 6758.042 113m24.351s 0m32.819s 0m0.899s
96 6701.73 0.04 0.15 6732.446 113m0.614s 0m32.101s 0m0.777s
""")

time2seconds(s) =
  let m = match(r"(.+)m(.+)s", s)
    parse(Float64, m.captures[1])*60+parse(Float64, m.captures[2])
  end

plot_opt(raw_data) =
  let data = sort(combine(groupby(raw_data, :Processes),
                          :RealTime => it->mean(map(time2seconds, it))),
                  :Processes)
    bar(string.(data[:,1]),
         data[:,2],
         legend=:none,
         markers=:auto,
         #ylimits=(0,180),
         xlabel="Processes",
         #color=:green,
         #xscale=:log10,
         ylabel="Time (s)")
  end

plt = plot_opt(opt_xnes)
saveplot(plt,"xnes1000")
```
\textoutput{plotopt1}

Results show that the optimization clearly benefits from the use of
multiple workers evaluating candidate solutions in parallel but only
up to eight processes. After that, there is no benefit. We then
repeated the same experiment but now using a five times larger number
of objective function evaluations, i.e., 5000. The results were the
following:

```julia:plotopt2
#hideall
#opt = bbsetup(displacement_obj; Method=:xnes, SearchRange = [(-6.0, 6.0), (-6.0, 6.0)], MaxFuncEvals = 5000, Workers = workers())

plt = plot_opt(bench_data("""
Processes StopTime Steps_per_second Evals_per_second OptTime RealTime UserTime SysTime
2 133190.0 0 0 0 2219m48s 0m0s 0m0s
4 66448.18 0.02 0.08 66454.99 1108m14.800s 0m35.658s 0m0.764s
8 33777.36 0.04 0.15 33783.924 563m37.545s 0m58.303s 0m1.454s
16 33226.69 0.04 0.15 33235.892 554m33.191s 0m33.010s 0m0.871s
32 33785.62 0.04 0.15 33798.45 563m56.404s 0m32.420s 0m0.717s
48 33542.42 0.04 0.15 33560.061 560m2.998s 0m33.508s 0m1.067s
64 33868.17 0.04 0.15 33890.237 565m34.886s 0m33.657s 0m1.247s
80 33400.07 0.04 0.15 33425.944 557m51.121s 0m32.613s 0m1.003s
96 33138.92 0.04 0.15 33169.674 553m37.801s 0m33.379s 0m1.041s
"""))
saveplot(plt,"xnes1000")
```
\textoutput{plotopt2}

As we can see, increasing the number of objective function evaluations
only scales the bar chart. The overall speedups are exactly the same.

We hypothesized that the cause for the lack of scalability was the
limited size of the population that was used by default in xNES. Given
that BlackBoxOptim fixes the population size at 50, we experimented
increasing this to 100 in the hope that it would allow the algorithm
to have more evaluations to divide among the workers. The following
plots illustrates the results for a one-thousand limit in the number
of function evaluations:

```julia:plotopt3
#hideall
#opt = bbsetup(displacement_obj; Method=:xnes, SearchRange=[(-6.0, 6.0), (-6.0, 6.0)], MaxFuncEvals=1000, PopulationSize=100, Workers=workers())

plt = plot_opt(bench_data("""
Processes StopTime Steps_per_second Evals_per_second OptTime RealTime UserTime SysTime
2 26741.22 0.01 0.04 26746.945 446m20.485s 0m33.765s 0m5.557s
4 13101.47 0.02 0.08 13107.262 219m0.522s 0m33.282s 0m5.648s
8 6783.39 0.04 0.15 6789.837 113m44.586s 1m2.184s 0m7.351s
16 6772.83 0.04 0.15 6781.835 113m38.535s 0m34.213s 0m6.184s
32 6742.70 0.04 0.15 6755.581 113m13.762s 0m33.719s 0m6.371s
48 6650.14 0.04 0.15 6667.443 111m47.097s 0m32.935s 0m6.323s
64 6637.45 0.04 0.15 6658.865 111m42.543s 223m20.020s 0m44.278s
"""))
saveplot(plt,"xnes1000pop100")
```
\textoutput{plotopt3}

Once again, the speedups seem to be limited to eight processes and
given that there were no expected gains after that, we stopped the
process after collecting data for up to 64 processes.

We then experimented increasing both the population size and the
number of function evaluations to, respectively, 500 and 5000.

```julia:plotopt6
#hideall
#opt = bbsetup(displacement_obj; Method=:xnes, SearchRange=[(-6.0, 6.0), (-6.0, 6.0)], MaxFuncEvals=5000, PopulationSize=500, Workers=workers())

plt = plot_opt(bench_data("""
Processes StopTime Steps_per_second Evals_per_second OptTime RealTime UserTime SysTime
2 131346.0 0 0 0 2189m6s 0m0s 0m0s
4 68098.63 0.02 0.07 68104.313 1135m37.980s 0m57.256s 1m29.594s
8 34128.00 0.04 0.15 34134.464 569m28.687s 0m57.995s 1m34.001s
16 34066.71 0.04 0.15 34075.057 568m31.238s 2m40.776s 1m36.928s
32 33536.74 0.04 0.15 33549.778 559m48.894s 1m0.333s 1m34.755s
48 33526.71 0.04 0.15 33544.316 559m45.777s 1m1.544s 1m34.427s
64 33554.69 0.04 0.15 33576.358 560m20.215s 1m1.307s 1m34.675s
80 33487.30 0.04 0.15 33513.25 559m19.562s 1m1.823s 1m34.290s
96 33175.78 0.04 0.15 33206.042 554m15.315s 1m1.331s 1m34.962s
"""))
saveplot(plt,"xnes500_5000")
```
\textoutput{plotopt6}

As visible, there are no significant differences. The optimization
seems not to scale beyond eight processes.

The next experiment was to increase the dimensionality of the design
space, by increasing the independent variables from two to three. Now,
besides the $X$ and $Y$ coordinates of the central node of the truss, we
also optimized its $Z$ coordinate, allowing it to vary between 1 and
20. We also decided to experiment running the process using just one
thread, to better understand the advantages of parallelization. Fixing
the maximum number of evaluations at 2000, we obtained the following
results:

```julia:plotopt5
#hideall
#opt = bbsetup(displacement_obj3; Method=:xnes, SearchRange = [(-6.0, 6.0), (-6.0, 6.0), (1.0, 20.0)], MaxFuncEvals = 2000,

plt = plot_opt(bench_data("""
Processes StopTime Steps_per_second Evals_per_second OptTime RealTime UserTime SysTime
1 53816.55 0.01 0.04 53821.47 897m37.442s 895m8.262s 2m12.626s
2 30723.26 0.01 0.07 30728.769 512m44.172s 0m36.939s 0m14.485s
4 15415.51 0.02 0.13 15421.022 257m34.989s 896m1.726s 2m28.686s
8 8014.55 0.04 0.25 8021.053 134m21.591s 257m43.612s 1m3.304s
16 7838.72 0.04 0.26 7847.56 131m24.990s 0m47.160s 0m55.770s
"""))
saveplot(plt,"xnes3V")
```
\textoutput{plotopt5}

Given the time it takes to produce these results, we stopped the
experiment as soon as we were sure that there were no more
improvements. Note the considerable gains obtained moving from one
process to two, to four, and to height, with an almost constant speedup
of two, but it clearly stops after we reach height processes.

Finally, we decided to experiment with a different optimization
algorithm, this time Separable Natural Evolution Strategy (sNES). We
used the initial set of variables (just the $X$ and $Y$ coordinates of
the central truss node), an initial population size of 500 and a
maximum number of objective function evaluations of 5000.

```julia:plotopt7
#hideall
#opt = bbsetup(displacement_obj; Method=:separable_nes, SearchRange = [(-6.0, 6.0), (-6.0, 6.0)], PopulationSize=500, MaxFuncEvals = 5000,

plt = plot_opt(bench_data("""
Processes StopTime Steps_per_second Evals_per_second OptTime RealTime UserTime SysTime
2 131653.0 0 0 0 2194m12s 0m0s 0m0s
4 44180.32 0.02 0.11 44183.87 736m58.052s 0m30.462s 0m0.853s
8 22385.47 0.04 0.22 22389.606 373m44.417s 367m0.174s 0m59.470s
16 22571.66 0.04 0.22 22578.332 376m53.987s 0m30.383s 0m1.400s
32 22396.59 0.04 0.22 22407.144 374m5.288s 0m30.275s 0m1.252s
48 22494.03 0.04 0.22 22509.223 375m50.909s 0m30.698s 0m1.504s
64 22261.78 0.04 0.22 22281.23 372m3.320s 0m30.651s 0m1.489s
80 22616.02 0.04 0.22 22639.678 378m6.548s 12m58.036s 1m54.225s
96 22169.91 0.04 0.23 22197.799 370m44.658s 0m30.396s 0m1.568s
"""))
saveplot(plt,"snes5000")
```
\textoutput{plotopt7}

In this case, there is an important speedup (3X) in the transition
from two to four processes, that is explainable, possibly, by the fact that
the transition is, in fact, from 1 worker to 3 workers, meaning that
we can triple the number of objective function evaluations being done
on each step. It is less clear why the previous experiments did not
show the same initial speedup. In the end, we were not impressed with
the speedups that we obtained from all of these experiments. We can
conclude that for the specific algorithms and optimization problems
that we studied, there is no justification to use more than eight
processes. The good news is that this is the typical number of
computing threads that are currently available in most off-the-shelf
hardware. The bad news is that it does not make the case for the use
of supercomputers, which have much larger numbers of threads.

There is, however, a silver lining. In all of these experiments, we
used just one computing node for each specific algorithm, but we
managed to use different computing nodes for different
experiments. This means that, in practice, the time needed to do the
entire set of experiments is not the sum of the time needed for each
experiment but the maximum of all those times, subject to the
limitation that we could only explore four computing nodes and to the
fact that there were other jobs competing for those
resources. Nevertheless, it demonstrates the potential gains that can
be obtained when addressing the No Free Lunch theorem, which states
that no optimization algorithm is better than all others in all
cases. The consequence is that multiple algorithms need to be tested
and the ability to use multiple computing nodes allows these tests to
be done simultaneously, thus taking no more time than the time needed
to run the slowest of them.

#
[<< Previous Chapter](/page3/)

[Next Chapter >>](/page5/)
