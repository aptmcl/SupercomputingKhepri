<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <script src="/SupercomputingKhepri/libs/plotly/plotly.min.js"></script> <link rel=stylesheet  href="/SupercomputingKhepri/libs/katex/katex.min.css"> <link rel=stylesheet  href="/SupercomputingKhepri/libs/highlight/github.min.css"> <link rel=stylesheet  href="/SupercomputingKhepri/css/franklin.css"> <link rel=stylesheet  href="/SupercomputingKhepri/css/tufte.css"> <link rel=stylesheet  href="/SupercomputingKhepri/css/latex.css"> <link rel=stylesheet  href="/SupercomputingKhepri/css/adjust.css"> <link rel=icon  href="/SupercomputingKhepri/assets/favicon.png"> <title>Architecture in the Supercomputing Era</title> <div id=layout > <div id=menu > <ul> <li><a href="/SupercomputingKhepri/">Home</a> <li><a href="/SupercomputingKhepri/menu1/">Code blocks</a> <li><a href="/SupercomputingKhepri/menu2/">More goodies</a> <li><a href="/SupercomputingKhepri/menu3/">Tags</a> </ul> </div> <div id=main > <div class=franklin-content > <h1 id=architecture_in_the_supercomputing_era ><a href="#architecture_in_the_supercomputing_era" class=header-anchor >Architecture in the Supercomputing Era</a></h1> <p><div class=franklin-toc ><ol><li><a href="#introduction">Introduction</a><li><a href="#commodity_hardware">Commodity Hardware</a><li><a href="#the_supercomputing_hardware">The Supercomputing Hardware</a><li><a href="#the_supercomputing_sofware">The Supercomputing Sofware</a><li><a href="#the_plan">The Plan</a><li><a href="#installing_software">Installing Software</a><li><a href="#recompiling_software">Recompiling Software</a><li><a href="#julia">Julia</a></ol></div> </p> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p>My research group has been working for many years in the combination between Architecture and Computer Science. More specifically, we have been researching in Algorithmic Design, Algorithmic Analysis, Algorithmic Optimization, and Algorithmic Visualization. Algorithmic Design focus on the use of algorithms that generate designs, particularly, building designs. Algorithmic Analysis deals with the automation of analysis processes, such as lighting analysis or structural analysis. Algorithmic Optimization takes advantage of the two previous areas to optimize building designs according to given metrics, e.g., structural performance. Finally, Algorithmic Visualization is concerned with the algorithmic exploration of cinematographic techniques to generate images and films of building designs.</p> <p>Some of the previous areas have considerable computational demands. Algorithmic optimization and Algorithmic Visualization, in particular, are extremely demanding from the computational point of view: it is not unusual to have processes running for weeks in high-performance computer workstations. Obviously, the typical duration of these processes makes it less likely that architects and engineers are eager to wait for so long for their completion and, thus, they end up not using them.</p> <p>However, when we consider the evolution of the performance of the computing systems, we verify that an enormous increase in computation power occurred in the last decades. First, by increasing the number of instructions a processors could execute in a given amount of time and, then, by increasing the number of processors. The software that nowadays runs on a mobile phone, decades ago required large rooms full of harware with huge energy demands.</p> <p>This shows that we should not take the currently available computational power as the norm but only as another data point in the trend for increasingly larger computational power. This point of view is particularly relevant because it allows us to forecast future computational power and to realize that what is nowadays out of reach for commodity hardware but is already possible in supercomputing devices will, in the near future, be possible in commodity hardware.</p> <p>It was with this perception that we submitted an application for the FCT Call on Advanced Computing Projects, which gave us the opportunity to use the High-Performance Computing &#40;HPC&#41; capability provided by one of Portugal&#39;s supercomputing centers. Our goal was to look at some of our previous and current research, from which we already had data regarding their computational demands, and reexecute the associated programs in a supercomputer, to assess the effective gains. It was also important for us to evaluate the experience of using a supercomputer, as these tend to run operating systems with very specific characteristics and that differ significantly from those of a typical off-the-shelf computer.</p> <h2 id=commodity_hardware ><a href="#commodity_hardware" class=header-anchor >Commodity Hardware</a></h2> <p>Throughout the time, our research has produced a series of programs and programming environments. Given the area, it is not surprising to verify that many of them are intended to be used through a graphical user interface. In general, for most of their activities, our researchers use laptops that have obvious computing power limitations.</p> <p>For the most demanding computations, the highest-powered system we used was a 2-CPU/16-core/64 GB RAM workstation running Windows-10. This workstation was used, mostly, for tasks where user attention was not critical, such as optimization and rendering. It was not unusual for some of these tasks to require days or weeks of computation.</p> <p>Despite the fact that, several years ago, these tasks would take months to complete, this was no consolation when results were needed as soon as possible. Nowadays, users do not want to wait more than one day and that is already assuming that the task will be done overnight so that results are available in the morning.</p> <h2 id=the_supercomputing_hardware ><a href="#the_supercomputing_hardware" class=header-anchor >The Supercomputing Hardware</a></h2> <p>Upon approval of our application to the FCT Call on Advanced Computing Projects, we were given access to the Cirrus supercomputer, more specifically, the <code>fct</code> partition containing four computing nodes, each node providing 96 AMD EPYC 7552 cores, running at 2.2 GHz and accessing 512 GB of RAM. In total, this partition allows 384 simultaneous threads of execution, using 2 TB of memory, although these would be constrained by the supercomputer topology and the available resources at each moment. In any case, this represents a significant amount of computing power when compared with current comodity hardware that, typicaly, can simultaneously execute only 8 threads of execution using 16 GB of RAM.</p> <p>It is also important to mention that users to not have direct access to the computing nodes. Instead, they have to use a front-end machine with an Intel Xeon CPU L5420 running at 2.5GHz with 32 GB of RAM.</p> <h2 id=the_supercomputing_sofware ><a href="#the_supercomputing_sofware" class=header-anchor >The Supercomputing Sofware</a></h2> <p>Despite the large differences between the hardware of the Cirrus supercomputer and that of a typical laptop, the differences in software were even bigger and caused the biggest headaches. First, because the supercomputer uses CentOS 7, an operating system that is very different from the most popular ones, such as Microsoft&#39;s Windows or Apple&#39;s MacOS. Second, because it mostly operates in <em>batch mode</em>, meaning that <em>scripts</em> must be submitted describing the intended executions and the resources needed, and there is no immediate feedback, for example, to report errors in the code. Fourth, the <em>batch mode</em> also implies that it only supports programs that do not require interacting with the user and, therefore, do not use a graphical user interface.</p> <h2 id=the_plan ><a href="#the_plan" class=header-anchor >The Plan</a></h2> <p>Given that the available HPC resources are running Linux variants which are very different from the Windows 10 operating system that constitutes the usual environment for Khepri, the first step would be to convert our software to Linux. Some of the required analysis tools already run in Linux &#40;e.g. Radiance, Frame3DD&#41; but others would need to be converted. We expect that this conversion would not need the use of the advanced computing resources except for testing.</p> <p>After that step, we planned to test the Julia programming language capabilities for HPC. Although there are studies that show that Julia is a good fit for those computing environments, we still need to get some experience in that kind of use.</p> <p>After having Julia running on the supercomputer, we planned to explore the Julia language to adapt our software to not only manage multiple parallel runs of sequential optimization algorithms but also use parallel optimization algorithms or open-source optimization frameworks supporting parallelization.</p> <p>Finally, if there was still time available, we would experiment running Khepri and some of their backends in the supercomputer to evaluate its scalability on different tasks, particularly, analysis, and visualization.</p> <p>However, given the fact that some of Khepri&#39;s backends only work in Windows, we had to select only those that we knew, in advance, that we could have running in Linux.</p> <p>To this end, the plan required the following instalation steps:</p> <ol> <li><p>Install the Julia language</p> <li><p>Install the KhepriBase package</p> <li><p>Install the BlackBoxOptim package, for multi- and single-objective optimization using meta-heuristic algorithms</p> <li><p>Install the KhepriFrame3DD package, for structural analysis</p> <li><p>Install the KhepriBlender and/or the KhepriPOVRay packages, for rendering</p> </ol> <p>Unfortunately, as we will see, installing even this small selection of programs was far from trivial.</p> <h2 id=installing_software ><a href="#installing_software" class=header-anchor >Installing Software</a></h2> <p>A major difficulty for accomplishing the plan is the lack of administrative privileges, as it prevents the system-wide installation of much needed libraries or software tools. Altough entirely understandable due to the shared nature of the system, lacking these priviliges makes it mandatory to use local installations. Fortunately, some of the critical software that we planned to use, such as the Julia programming language, can be installed locally.</p> <p>Initially, we tried to use the release candidate version of Julia version 1.6 because it promised to solve a pre-compilation problem that occurred when multiple simultaneous Julia processes attempted to pre-compile the software, triggering conflits in the saving of the compiled code to disk. However, this version caused problems related to the foreign function interface that was critical for calling our own DLL implementation of the structural analysis package Frame3DD.</p> <p>After these failures, we went back to version 1.5.3, which we installed locally, using the official version for Linux and FreeBSD, hoping that the mentioned synchronization problems would not prevent us from doing the planned experiments.</p> <p>Unfortunately, not all software can be installed this way, making it impossible to do some of the planned experiments. The first casualty was Blender. Although there is a CentOS version of Blender, its installation requires administrative privileges. We spend some time trying alternative ways to install Blender but, given the limited time available, we moved on to the next alternative – POVRay.</p> <h2 id=recompiling_software ><a href="#recompiling_software" class=header-anchor >Recompiling Software</a></h2> <p>Not all software that is available for Linux &#40;or, more specifically, Ubuntu&#41; can directly run on the supercomputer. Some can only run after being recompiled for CentOS 7. Given the difficulty of using the frontend for anything more complex than just editing files or submitting jobs, we decided to recompile the software on our own machines and only move the resulting binaries to the supercomputer. In the begining we were doing this using a Ubuntu installation running on Windows Subsystem for Linux &#40;WSL&#41;, which we expect would be very similar to CentOS. However, we quickly discovered that there were errors related to differences in the libraries of Ubuntu and CentOS</p> <ol start=7 > <li><p>To avoid being forced to recompile the software, we initially</p> </ol> <p>attempted to solve these dependency errors but soon realized that it would not end up well.</p> <p>In the end, to avoid errors due to different software versions, we installed the exact same operating system on a virtual machine. This allowed us to more easily recompile the software, and only after successfully testing them on our own virtual machine, to move it to the supercomputer. At that moment, however, we discovered that despite running the exact same operating system, executing some of the recompiled programs in the frontend computer triggered an <code>Illegal instruction</code> error. After much unsuccessful debuging, we discovered that these errors did not occur when the programs were executed in the computing nodes.</p> <p>Unfortunately, the time and effort spent making just one of the programs run on the supercomputer consumed a significant fraction of the time that was given us to use the machine. To avoiding wasting the entire time just on the task of making the programs run, we decided to focus on those programs that we had already running and we start collecting statistics of their execution using a different number of processing units.</p> <h2 id=julia ><a href="#julia" class=header-anchor >Julia</a></h2> <p>The first tests attempted to determine how the Julia language implementation scales across multiple cores. The following Julia program computes an approximation of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> using the classical Monte Carlo approach of sampling points on a square that circunscribes a circle of radius <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>. In that case, the area of the circle is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mi>r</mi><mtext>²</mtext></mrow><annotation encoding="application/x-tex">\pi r²</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class=mord >²</span></span></span></span> while the area of the square is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mn>2</mn><mi>r</mi><mo stretchy=false >)</mo><mtext>²</mtext><mo>=</mo><mn>4</mn><mi>r</mi><mtext>²</mtext></mrow><annotation encoding="application/x-tex">(2r)²=4r²</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class=mord >2</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class=mclose >)</span><span class=mord >²</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >4</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class=mord >²</span></span></span></span>. The ratio between these areas is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>π</mi><mi>r</mi><mtext>²</mtext></mrow><mrow><mn>4</mn><mi>r</mi><mtext>²</mtext></mrow></mfrac><mo>=</mo><mfrac><mi>π</mi><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{\pi r²}{4r²}=\frac{\pi}{4}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.040392em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight">²</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight">²</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.040392em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, which means that, independently of the radius of the circle, a uniformly distributed sample of points over the square will have <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>π</mi><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{\pi}{4}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.040392em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> points inside the circle.</p> <p>Instead of computing the approximation to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> &#40;whose value we already know&#41;, we prefer to compute the absolute error.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Statistics

approx_pi(n) =
  <span class=hljs-keyword >let</span> count = <span class=hljs-number >0</span>
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:n
      count += (rand()^<span class=hljs-number >2</span> + rand()^<span class=hljs-number >2</span>) &lt;= <span class=hljs-number >1</span>
    <span class=hljs-keyword >end</span>
    abs(<span class=hljs-number >4</span>*count/n - <span class=hljs-literal >pi</span>)
  <span class=hljs-keyword >end</span></code></pre> <p>Given the just-in-time compilation strategy used by Julia, we decided to do some preliminary computations to force the compilation and only then a benchmark is started. The benchmark computes approximations to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> with a series of exponentially increasing number of iterations. We evaluate the time spent with <code>@timev</code>:</p> <pre><code class="julia hljs"><span class=hljs-comment ># Force compilation:</span>
approx_pi(<span class=hljs-number >100</span>)

<span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:<span class=hljs-number >10</span>
  println(<span class=hljs-string >&quot;approx_pi(<span class=hljs-subst >$(<span class=hljs-number >10</span>^i)</span>):&quot;</span>, <span class=hljs-meta >@timev</span> approx_pi(<span class=hljs-number >10</span>^i))
<span class=hljs-keyword >end</span></code></pre> <p>The benchmark results are the following:</p> <div id=fdppjk  style="width:600px;height:350px"></div> <script> var fig = {"layout":{"showlegend":true,"xaxis":{"showticklabels":true,"gridwidth":0.5,"tickvals":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"visible":true,"ticks":"inside","range":[0.73,10.27],"domain":[0.0,0.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Iterations","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["10^1","10^2","10^3","10^4","10^5","10^6","10^7","10^8","10^9","10^10"],"zeroline":false,"type":"log","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"y"},"paper_bgcolor":"rgba(255, 255, 255, 1.000)","annotations":[],"height":330,"margin":{"l":0,"b":20,"r":0,"t":20},"plot_bgcolor":"rgba(255, 255, 255, 1.000)","yaxis":{"showticklabels":true,"gridwidth":0.5,"tickvals":[0.0,20.0,40.0,60.0,80.0],"visible":true,"ticks":"inside","range":[-5.0,80.0],"domain":[1.0,1.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Time (s)","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["0","20","40","60","80"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"x"},"legend":{"borderwidth":1,"tracegroupgap":0,"font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"title":{"font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"text":""},"traceorder":"normal","x":0.07,"yanchor":"top","xanchor":"left","bordercolor":"rgba(0, 0, 0, 1.000)","bgcolor":"rgba(255, 255, 255, 1.000)","y":1.0},"width":640},"frames":[],"data":[{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"Single threaded","zmin":null,"legendgroup":"Single threaded","marker":{"symbol":"circle","color":"rgba(0, 154, 250, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 154, 250, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[8.0e-6,3.0e-6,9.0e-6,7.4e-5,0.000754,0.007515,0.074811,0.749354,7.493605,75.014382],"type":"scatter"}]}; CONTAINER = document.getElementById('fdppjk'); Plotly.newPlot(CONTAINER, fig.data, fig.layout) </script> <p>It is relevant to note that despite aparent exponential growth, the scale is logarithmic and, thus, the computation time grows linearly with the number of iterations.</p> <p>The next step is to repeat the same computation but using parallel processing. To this end, Julia supports multi-threading and distributed computing. Multi-threading allows multiple tasks to run simultaneously on more than one thread or CPU core, sharing memory, while distributed computing runs multiple processes with separate memory spaces, possibly on different machines. Given that Khepri is not thread-safe, we were particularly interested in testing the distributed computing capabilities. These are provided by the <code>Distributed</code> standard library as well as external packages such as <code>MPI.jl</code> and <code>DistributedArrays.jl</code>.</p> <p>The <code>Distributed</code> approach is based on the idea that one <em>master</em> process launches a set of <em>slave</em> processes, called workers, using the <code>addprocs</code> function, to which it distributes units of work, waiting for their completion. Despite being part of the standard library, the <code>Distributed</code> module must be explicitly loaded on the master process to access the <code>addprocs</code> function. The module is automatically loaded on the worker processes.</p> <p>The next fragment of code demonstrate the creation of workers. We take the number of processes <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> that was passed as a command-line argument and we create <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span></span></span></span> additional workers so that the master and the slaves use all available resources.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Distributed

addprocs(parse(<span class=hljs-built_in >Int</span>, <span class=hljs-literal >ARGS</span>[<span class=hljs-number >1</span>])-<span class=hljs-number >1</span>)</code></pre> <p>Despite the simplicity of the <code>addprocs</code> function, there is a lot going on behind the scenes. Immediatly after its creation, each of the workers creates a TCP/IP connection, writes on standard output the corresponding host and port, and starts listening on that port. The master receives the output of each worker and completes the TCP/IP connection to each one. Then, it informs each worker of the connection point of all other workers, so that they can establish connections between themselves. To do this, each worker connects to all workers whose id is less than its own id.</p> <p>Given that all these connections require time to establish, we decided to measure its impact in the time and allocate memory as the number of processes is increased. The results are the following:</p> <div id=fdpuys  style="width:600px;height:350px"></div> <script> var fig = {"layout":{"paper_bgcolor":"rgba(255, 255, 255, 1.000)","height":330,"yaxis2":{"showticklabels":true,"gridwidth":0.5,"tickvals":[0.0,5.0,10.0,15.0,20.0,25.0,30.0,35.0],"visible":true,"ticks":"inside","range":[0.0,35.0],"domain":[1.0,1.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Memory (MiB)","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["0","5","10","15","20","25","30","35"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"x2"},"yaxis1":{"showticklabels":true,"gridwidth":0.5,"tickvals":[0.0,0.5,1.0,1.5,2.0,2.5],"visible":true,"ticks":"inside","range":[0.0,2.5],"domain":[1.0,1.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Time (s)","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["0.0","0.5","1.0","1.5","2.0","2.5"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"x1"},"annotations":[],"plot_bgcolor":"rgba(0, 0, 0, 0.000)","showlegend":true,"xaxis1":{"showticklabels":true,"gridwidth":0.5,"tickvals":[2.0,4.0,8.0,16.0,32.0,48.0,64.0,80.0,96.0],"visible":true,"ticks":"inside","range":[-0.8199999999999998,98.82],"domain":[0.0,0.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Processes","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["2","4","8","16","32","48","64","80","96"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"y1"},"legend":{"borderwidth":1,"tracegroupgap":0,"font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"title":{"font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"text":""},"traceorder":"normal","x":0.07,"yanchor":"top","xanchor":"left","bordercolor":"rgba(0, 0, 0, 1.000)","bgcolor":"rgba(255, 255, 255, 1.000)","y":1.0},"xaxis2":{"showticklabels":false,"gridwidth":0.5,"visible":true,"ticks":"inside","range":[-0.8199999999999998,98.82],"domain":[0.0,0.0],"linecolor":"rgba(0, 0, 0, 1.000)","showgrid":false,"title":"","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","zeroline":false,"type":"-","zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"y2"},"margin":{"l":0,"b":20,"r":0,"t":20},"width":640},"frames":[],"data":[{"xaxis":"x1","colorbar":{"title":""},"yaxis":"y1","x":[2.0,4.0,8.0,16.0,32.0,48.0,64.0,80.0,96.0],"showlegend":true,"mode":"markers","name":"Time","zmin":null,"legendgroup":"Time","marker":{"symbol":"circle","color":"rgba(0, 154, 250, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"y":[1.078188,1.205602,1.480043,1.379302,1.375842,1.691627,1.737718,1.843256,2.059247],"type":"scatter"},{"xaxis":"x1","colorbar":{"title":""},"yaxis":"y1","x":[2.0,96.0],"showlegend":false,"mode":"lines+markers","name":"","zmin":null,"legendgroup":"","marker":{"symbol":"circle","color":"rgba(0, 154, 250, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 154, 250, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[1.2224176887170155,2.029080897588717],"type":"scatter"},{"xaxis":"x2","colorbar":{"title":""},"yaxis":"y2","x":[2.0,4.0,8.0,16.0,32.0,48.0,64.0,80.0,96.0],"showlegend":true,"mode":"lines+markers","name":"Memory","zmin":null,"legendgroup":"Memory","marker":{"symbol":"circle","color":"rgba(0, 128, 0, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 128, 0, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[1.148,1.828,3.196,5.945,11.478,17.115,22.81,28.583,34.435],"type":"scatter"}]}; CONTAINER = document.getElementById('fdpuys'); Plotly.newPlot(CONTAINER, fig.data, fig.layout) </script> <p>This shows using multiple processes entails a overhead with a fixed part of around one second and a variable part of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0</span><span class=mord >.</span><span class=mord >0</span><span class=mord >1</span></span></span></span> seconds per process.</p> <p>The next step is to divide the work among the workers. To that end, each needs to know what it is supposed to be computed and this is another area where Julia shines. The macro <code>@everywhere</code> allows the master to make requests to all workers. In our case, we need each worker to define the function <code>approx_pi</code> that computes the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> approximation using the Monte Carlo method. To force Just-In-Time compilation on each worker, we also request a corresponding function call.</p> <pre><code class="julia hljs"><span class=hljs-meta >@everywhere</span> approx_pi(n) =
  <span class=hljs-keyword >let</span> count = <span class=hljs-number >0</span>
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:n
      count += (rand()^<span class=hljs-number >2</span> + rand()^<span class=hljs-number >2</span>) &lt;= <span class=hljs-number >1</span>
    <span class=hljs-keyword >end</span>
    abs(<span class=hljs-number >4</span>*count/n - <span class=hljs-literal >pi</span>)
  <span class=hljs-keyword >end</span>

<span class=hljs-comment ># Compilation:</span>
<span class=hljs-meta >@everywhere</span> approx_pi(<span class=hljs-number >100</span>)</code></pre> <p>Finally, to compute the approximation, we take advantage of Julia&#39;s higher-level parallel operations, namely, <code>pmap</code>, which maps a function over an array, but arranging for the applications to be done in parallel by distributing the array values among the workers. We defined the <code>p_approxi_pi</code> function that helps the distribution by dividing the intended number of iterations between the workers and then computing the <code>mean</code> of the results that came from the workers.</p> <pre><code class="julia hljs">p_approx_pi(n) =
  mean(pmap(n-&gt;approx_pi(n),
       [n/nworkers() <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:nworkers()]))</code></pre> <p>To evaluate the effectiveness of this strategy, we experimented a series of computations using an exponentially larger number of iterations, using an increasingly larger number of parallel processes.</p> <pre><code class="julia hljs"><span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:<span class=hljs-number >10</span>
  println(<span class=hljs-string >&quot;p_approx_pi(<span class=hljs-subst >$(<span class=hljs-number >10</span>^i)</span>):&quot;</span>, <span class=hljs-meta >@timev</span> p_approx_pi(<span class=hljs-number >10</span>^i))
<span class=hljs-keyword >end</span></code></pre> <p>Note that, with this scheme, when we use two processes, we are in fact using just one worker, as the other one is just managing the distribution of work and collection of results. In the next plot, we also superimpose the results for the single-threaded case.</p> <div id=fdpual  style="width:600px;height:350px"></div> <script> var fig = {"layout":{"showlegend":true,"xaxis":{"showticklabels":true,"gridwidth":0.5,"tickvals":[100.0,10000.0,1.0e6,1.0e8,1.0e10],"visible":true,"ticks":"inside","range":[0.73,10.27],"domain":[0.0,0.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Iterations","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["10^2","10^4","10^6","10^8","10^10"],"zeroline":false,"type":"log","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"y"},"paper_bgcolor":"rgba(255, 255, 255, 1.000)","annotations":[],"height":330,"margin":{"l":0,"b":20,"r":0,"t":20},"plot_bgcolor":"rgba(255, 255, 255, 1.000)","yaxis":{"showticklabels":true,"gridwidth":0.5,"tickvals":[0.0,20.0,40.0,60.0,80.0],"visible":true,"ticks":"inside","range":[0.0,80.0],"domain":[1.0,1.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Time (s)","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["0","20","40","60","80"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"x"},"legend":{"borderwidth":1,"tracegroupgap":0,"font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"title":{"font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"text":"# Processes"},"traceorder":"normal","x":0.07,"yanchor":"top","xanchor":"left","bordercolor":"rgba(0, 0, 0, 1.000)","bgcolor":"rgba(255, 255, 255, 1.000)","y":1.0},"width":640},"frames":[],"data":[{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"1","zmin":null,"legendgroup":"1","marker":{"symbol":"circle","color":"rgba(0, 154, 250, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 154, 250, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[8.0e-6,3.0e-6,9.0e-6,7.4e-5,0.000754,0.007515,0.074811,0.749354,7.493605,75.014382],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"2","zmin":null,"legendgroup":"2","marker":{"symbol":"square","color":"rgba(227, 111, 71, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(227, 111, 71, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.856018,0.000391,0.000182,0.000178,0.000856,0.007842,0.080284,0.776677,8.230821,77.264732],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"4","zmin":null,"legendgroup":"4","marker":{"symbol":"diamond","color":"rgba(62, 164, 78, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(62, 164, 78, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.847039,0.003264,0.000225,0.000153,0.000414,0.002873,0.026081,0.257399,2.7517,26.270629],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"8","zmin":null,"legendgroup":"8","marker":{"symbol":"triangle-up","color":"rgba(195, 113, 210, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(195, 113, 210, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.854364,0.001206,0.00041,0.00031,0.000461,0.001537,0.011333,0.110858,1.147449,11.570491],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"16","zmin":null,"legendgroup":"16","marker":{"symbol":"triangle-down","color":"rgba(172, 142, 24, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(172, 142, 24, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[1.089487,0.001074,0.000708,0.00069,0.000682,0.001329,0.006278,0.05676,0.562188,5.599749],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"32","zmin":null,"legendgroup":"32","marker":{"symbol":"cross","color":"rgba(0, 170, 174, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 170, 174, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.896568,0.002596,0.001506,0.001533,0.001501,0.001477,0.003643,0.026056,0.251256,2.518703],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"48","zmin":null,"legendgroup":"48","marker":{"symbol":"x","color":"rgba(237, 94, 147, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(237, 94, 147, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.988248,0.003823,0.002412,0.002424,0.002398,0.002382,0.003472,0.01811,0.169489,1.745023],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"64","zmin":null,"legendgroup":"64","marker":{"symbol":"pentagon","color":"rgba(198, 130, 37, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(198, 130, 37, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.95072,0.004167,0.003167,0.003195,0.003153,0.003184,0.00351,0.014892,0.130532,1.30631],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"80","zmin":null,"legendgroup":"80","marker":{"symbol":"hexagon","color":"rgba(0, 169, 141, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 169, 141, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.960334,0.005236,0.00412,0.004182,0.00417,0.004118,0.004086,0.017604,0.15506,1.173751],"type":"scatter"},{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[10.0,100.0,1000.0,10000.0,100000.0,1.0e6,1.0e7,1.0e8,1.0e9,1.0e10],"showlegend":true,"mode":"lines+markers","name":"96","zmin":null,"legendgroup":"96","marker":{"symbol":"octagon","color":"rgba(142, 151, 30, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(142, 151, 30, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[0.947769,0.006393,0.00502,0.005109,0.064166,0.004894,0.004888,0.013053,0.103313,0.954526],"type":"scatter"}]}; CONTAINER = document.getElementById('fdpual'); Plotly.newPlot(CONTAINER, fig.data, fig.layout) </script> <p>Results show that two processes, i.e., having just one worker doing all the work, is very similar to the single-threaded case. The performance impact is just 2.6&#37;. However it is not all good news, as the results also show that it only pays off to parallelize when the number of iterations reaches <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>8</mn></msup></mrow><annotation encoding="application/x-tex">10^8</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8141079999999999em;vertical-align:0em;"></span><span class=mord >1</span><span class=mord ><span class=mord >0</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span>.</p> <p>On the other hand, when we compare the time it takes the entire experiment for a given number of processes, the results are a bit surprising:</p> <div id=fdpdbp  style="width:600px;height:350px"></div> <script> var fig = {"layout":{"showlegend":false,"xaxis":{"showticklabels":true,"gridwidth":0.5,"tickvals":[2.0,4.0,8.0,16.0,32.0,48.0,64.0,80.0,96.0],"visible":true,"ticks":"inside","range":[-0.8199999999999998,98.82],"domain":[0.0,0.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Processes","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["2","4","8","16","32","48","64","80","96"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"y"},"paper_bgcolor":"rgba(255, 255, 255, 1.000)","annotations":[],"height":330,"margin":{"l":0,"b":20,"r":0,"t":20},"plot_bgcolor":"rgba(255, 255, 255, 1.000)","yaxis":{"showticklabels":true,"gridwidth":0.5,"tickvals":[0.0,30.0,60.0,90.0,120.0,150.0,180.0],"visible":true,"ticks":"inside","range":[0.0,180.0],"domain":[1.0,1.0],"tickmode":"array","linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"Time (s)","mirror":false,"tickangle":0,"showline":true,"gridcolor":"rgba(0, 0, 0, 0.100)","titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgb(0, 0, 0)","ticktext":["0","30","60","90","120","150","180"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"zerolinecolor":"rgba(0, 0, 0, 1.000)","anchor":"x"},"width":640},"frames":[],"data":[{"xaxis":"x","colorbar":{"title":""},"yaxis":"y","x":[2.0,4.0,8.0,16.0,32.0,48.0,64.0,80.0,96.0],"showlegend":true,"mode":"lines+markers","name":"2","zmin":null,"legendgroup":"2","marker":{"symbol":"circle","color":"rgba(0, 154, 250, 1.000)","line":{"color":"rgba(0, 0, 0, 1.000)","width":1},"size":8},"zmax":null,"line":{"color":"rgba(0, 154, 250, 1.000)","width":1,"dash":"solid","shape":"linear"},"y":[174.818,117.889,101.636,96.311,95.354,96.136,95.539,96.951,98.881],"type":"scatter"}]}; CONTAINER = document.getElementById('fdpdbp'); Plotly.newPlot(CONTAINER, fig.data, fig.layout) </script> <p>Now, we see that despite the considerable gains obtained, almost halving the time needed, it only pays off to use up to 16 processes. Our guess for the lack of speedup after 16 processes is that the time spent starting processes and managing them nullifies the gains of the parallelization. In order to improve these results, it might be necessary to use a different process topology.</p> <div class=page-foot > <div class=copyright > &copy; António Menezes Leitão. Last modified: March 11, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div>